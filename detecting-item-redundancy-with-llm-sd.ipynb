{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/elisamens/detecting-item-redundancy-with-llm-sd?scriptVersionId=136927962\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"Code to:\n\nMens, E. C. (2023). Assessing Item Redundancy in Psychological Surveys by Using Large Language Models based Similarity Detection (LLM-SD) [Unpublished Masterthesis]. University of Amsterdam.","metadata":{}},{"cell_type":"code","source":"!pip install openai --root-user-action=ignore\n!pip install -U sentence-transformers --root-user-action=ignore\n!pip install researchpy --root-user-action=ignore","metadata":{"_kg_hide-output":true,"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-07-16T10:54:44.54424Z","iopub.execute_input":"2023-07-16T10:54:44.545126Z","iopub.status.idle":"2023-07-16T10:55:33.419356Z","shell.execute_reply.started":"2023-07-16T10:54:44.545074Z","shell.execute_reply":"2023-07-16T10:55:33.418213Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting openai\n  Downloading openai-0.27.8-py3-none-any.whl (73 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.6/73.6 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from openai) (4.4.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from openai) (4.64.1)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.7/site-packages (from openai) (3.8.3)\nRequirement already satisfied: requests>=2.20 in /opt/conda/lib/python3.7/site-packages (from openai) (2.28.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.7/site-packages (from requests>=2.20->openai) (2.1.1)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests>=2.20->openai) (1.26.14)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests>=2.20->openai) (2022.12.7)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests>=2.20->openai) (3.4)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from aiohttp->openai) (1.3.3)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.7/site-packages (from aiohttp->openai) (4.0.2)\nRequirement already satisfied: asynctest==0.13.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->openai) (0.13.0)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->openai) (1.8.2)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.7/site-packages (from aiohttp->openai) (6.0.4)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->openai) (22.2.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.7/site-packages (from aiohttp->openai) (1.3.1)\nInstalling collected packages: openai\nSuccessfully installed openai-0.27.8\nCollecting sentence-transformers\n  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: transformers<5.0.0,>=4.6.0 in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (4.27.4)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (4.64.1)\nRequirement already satisfied: torch>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (1.13.0+cpu)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (0.14.0+cpu)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (1.21.6)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (1.0.2)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (1.7.3)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (3.2.4)\nRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (0.1.97)\nRequirement already satisfied: huggingface-hub>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (0.13.3)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.28.2)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (23.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.4.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.9.0)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (6.0)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.11.4)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2021.11.10)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.7/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.13.2)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from nltk->sentence-transformers) (1.16.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->sentence-transformers) (3.1.0)\nRequirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->sentence-transformers) (1.2.0)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.7/site-packages (from torchvision->sentence-transformers) (9.4.0)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->huggingface-hub>=0.4.0->sentence-transformers) (3.11.0)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2022.12.7)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.1.1)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (1.26.14)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.4)\nBuilding wheels for collected packages: sentence-transformers\n  Building wheel for sentence-transformers (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125938 sha256=9f7c0b371899a51d8fd79bfc2886802e1c8306c64d0080f22bd8806276d5e749\n  Stored in directory: /root/.cache/pip/wheels/83/71/2b/40d17d21937fed496fb99145227eca8f20b4891240ff60c86f\nSuccessfully built sentence-transformers\nInstalling collected packages: sentence-transformers\nSuccessfully installed sentence-transformers-2.2.2\nCollecting researchpy\n  Downloading researchpy-0.3.5-py3-none-any.whl (33 kB)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from researchpy) (1.21.6)\nRequirement already satisfied: patsy in /opt/conda/lib/python3.7/site-packages (from researchpy) (0.5.3)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from researchpy) (1.3.5)\nRequirement already satisfied: statsmodels in /opt/conda/lib/python3.7/site-packages (from researchpy) (0.13.5)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from researchpy) (1.7.3)\nRequirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas->researchpy) (2.8.2)\nRequirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas->researchpy) (2022.7.1)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from patsy->researchpy) (1.16.0)\nRequirement already satisfied: packaging>=21.3 in /opt/conda/lib/python3.7/site-packages (from statsmodels->researchpy) (23.0)\nInstalling collected packages: researchpy\nSuccessfully installed researchpy-0.3.5\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Import libraries","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport openai\nfrom openai.embeddings_utils import get_embedding #Open Ai embeddings\nfrom sentence_transformers import SentenceTransformer #Sbert embeddings\nfrom numpy.linalg import norm # used for cosine function \nimport tensorflow_hub as hub #USE embeddings\nimport tensorflow as tf #USE embeddings\nimport tensorflow_datasets as tfds #USE embeddings\n","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-07-16T10:55:56.739777Z","iopub.execute_input":"2023-07-16T10:55:56.740646Z","iopub.status.idle":"2023-07-16T10:55:56.754872Z","shell.execute_reply.started":"2023-07-16T10:55:56.740594Z","shell.execute_reply":"2023-07-16T10:55:56.75334Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"## Import data","metadata":{}},{"cell_type":"code","source":"path = \"/kaggle/input/constructs-items/\"\nitems = pd.read_excel('/kaggle/input/items-original/Constructs_items.xlsx')\nitems = items.loc[0:319, ('Type of construct', 'Construct', 'Measure', 'Item_English', 'Answer type')]\n\n# Selecting relevant columns, and remove empty rows\ndf = items[['Type of construct', 'Construct', 'Measure', 'Item_English']]\n\n# Converting into strings & removing line breaks \ndf.loc[:,(\"Item_English\")] = df.loc[:,(\"Item_English\")].astype(str).apply(lambda x: ' '.join(x.split('\\n')))","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-07-16T10:55:59.565974Z","iopub.execute_input":"2023-07-16T10:55:59.566444Z","iopub.status.idle":"2023-07-16T10:55:59.705087Z","shell.execute_reply.started":"2023-07-16T10:55:59.566402Z","shell.execute_reply":"2023-07-16T10:55:59.704002Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"## The Models","metadata":{}},{"cell_type":"markdown","source":"### 1. Ada Embeddings Open Ai\n\n#### Model setup","metadata":{}},{"cell_type":"code","source":"embedding_model = \"text-embedding-ada-002\"\nembedding_encoding = \"cl100k_base\"  # this the encoding for text-embedding-ada-002\nopenai.api_key = x # personal API key\nembedding_name = \"ada_embeddings\"","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-05-23T08:29:51.206122Z","iopub.execute_input":"2023-05-23T08:29:51.206822Z","iopub.status.idle":"2023-05-23T08:29:51.216497Z","shell.execute_reply.started":"2023-05-23T08:29:51.206765Z","shell.execute_reply":"2023-05-23T08:29:51.214095Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Embeddings","metadata":{}},{"cell_type":"code","source":"df[embedding_name] = df[\"Item_English\"].apply(lambda x: get_embedding(x, engine = embedding_model))\ndf.to_csv(embedding_name + '.csv')","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-05-23T08:29:53.237903Z","iopub.execute_input":"2023-05-23T08:29:53.238441Z","iopub.status.idle":"2023-05-23T08:34:15.117317Z","shell.execute_reply.started":"2023-05-23T08:29:53.238396Z","shell.execute_reply":"2023-05-23T08:34:15.115575Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Cosine Similarity Matrix","metadata":{}},{"cell_type":"code","source":"#defining cosine function\ndef cosine(x, y):\n    cosine = np.dot(x, y) / (norm(x) * norm(y))\n    return cosine\n\n#setting up df for cosine based on OpenAi\nCSI_ada = df[['Item_English', embedding_name]]\n\nfor i in range(len(CSI_ada)) :\n    x = CSI_ada.iloc[i,1]\n    z = CSI_ada.apply(lambda row: (cosine(row['ada_embeddings'], x)), axis=1)\n    col_name = str(i) + '. ' + str(CSI_ada.iloc[i,0])\n    CSI_ada.loc[:, col_name] = z\n\nCSI_ada.to_csv(\"CSI_ada.csv\")    \nprint(\"\\n---- Output: cosine similarity of items by ada ----\\n\")\n","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-05-23T08:39:26.10721Z","iopub.execute_input":"2023-05-23T08:39:26.108872Z","iopub.status.idle":"2023-05-23T08:41:19.330765Z","shell.execute_reply.started":"2023-05-23T08:39:26.1088Z","shell.execute_reply":"2023-05-23T08:41:19.329393Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Cosine Similarity Ranking of Items ","metadata":{}},{"cell_type":"code","source":"ranking_ada = CSI_ada\n\n# Drop embedding column\nranking_ada = ranking_ada.drop(['ada_embeddings'], axis=1)\n\n# Create Long format\nranking_ada = pd.DataFrame({ 'Item_2': np.tile(ranking_ada.columns, len(ranking_ada)), 'Item_1': ranking_ada.Item_English.repeat(ranking_ada.shape[1]), 'CSI': ranking_ada.values.ravel()})\nranking_ada = ranking_ada[ranking_ada['Item_2'] != 'Item_English']\n\n#Adding index columns\nranking_ada['Index_1'] = ranking_ada.index\nranking_ada['Index_2'], ranking_ada['Item_2'] = ranking_ada['Item_2'].str.split('.', 1).str\nranking_ada['Index_2'] = ranking_ada['Index_2'].astype(int)\n\n# Rearrange column and sort values \nranking_ada = ranking_ada[[\"Index_1\",\"Item_1\",\"Index_2\",'Item_2', 'CSI']]\nranking_ada = ranking_ada.sort_values(by = ['CSI'], ascending = False, ignore_index=True)\n\n# Drop row if items are the same \nranking_ada = ranking_ada[ranking_ada['Index_1'] != ranking_ada['Index_2']]\nranking_ada.reset_index(inplace=True, drop=True)\n\n#Save data\nranking_ada.to_csv('ranking_ada_duplicates.csv', index=False)\n#ranking_ada.to_excel('ranking_ada_duplicates.xlsx') \n\nprint(\"\\n----Output: ranking by ada with duplicates in Long Format ----\\n\")\n\n# removing dupclite items pairs e.g. 35-36 & 36-35\nranking_ada = ranking_ada[['Index_1', 'Item_1', 'Index_2', 'Item_2', 'CSI']][::2]\nranking_ada.reset_index(inplace=True, drop=True)\n\n#Save data\nranking_ada.to_csv('ranking_ada.csv', index=False)\n#ranking_ada.to_excel('ranking_ada.xlsx') \n\nprint(\"\\n----Output: ranking by ada in long format----\\n\")\n","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-05-23T08:41:29.467697Z","iopub.execute_input":"2023-05-23T08:41:29.469143Z","iopub.status.idle":"2023-05-23T08:41:32.521549Z","shell.execute_reply.started":"2023-05-23T08:41:29.469069Z","shell.execute_reply":"2023-05-23T08:41:32.51999Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Average Embeddings per Construct Type, Construct and Measurement","metadata":{}},{"cell_type":"code","source":"test = df\n#split embedding over multiple columns and concatenate them with original columns\ntest = pd.concat([test, test[\"ada_embeddings\"].apply(pd.Series)], axis = 1)\n\n#average embedding vector per ...\nconstructtype_ada_embeddings = test.groupby(\"Type of construct\").mean()\nconstructtype_ada_embeddings.reset_index(inplace=True)\nconstructtype_ada_embeddings.to_csv(\"constructtype_ada_embeddings.csv\") \nprint(\"\\n---- Output: Average Embeddings of Construct Type by ada ----\\n\")\n\n\nconstruct_ada_embeddings = test.groupby(\"Construct\").mean()\nconstruct_ada_embeddings.reset_index(inplace=True)\nconstruct_ada_embeddings.to_csv(\"construct_ada_embeddings.csv\") \nprint(\"\\n---- Output: Average Embeddings of Construct by ada ----\\n\")\n\n\nmeasurement_ada_embeddings = test.groupby(\"Measure\").mean()\nmeasurement_ada_embeddings.reset_index(inplace=True)\nmeasurement_ada_embeddings.to_csv(\"measurement_ada_embeddings.csv\") \nprint(\"\\n---- Output: Average Embeddings of Measurement by ada ----\\n\")\n\n\n# cosine similarity between Type of construct\nconstructtype_ada_CSI = constructtype_ada_embeddings[['Type of construct']]\ndel constructtype_ada_embeddings['Type of construct']\n\nfor i in range(len(constructtype_ada_embeddings)) :\n    x = constructtype_ada_embeddings.iloc[i,:]\n    z = constructtype_ada_embeddings.apply(lambda row: (cosine(row, x)), axis=1)\n    col_name = str(constructtype_ada_CSI.iloc[i,0])\n    constructtype_ada_CSI.loc[:, col_name] = z\nconstructtype_ada_CSI.to_csv(\"constructtype_ada_CSI.csv\")    \nprint(\"\\n---- Output: Cosine Similiarity Construct Type by ada ----\\n\")\n\n# cosine similarity between construct\nconstruct_ada_CSI = construct_ada_embeddings[['Construct']]\ndel construct_ada_embeddings['Construct']\n\nfor i in range(len(construct_ada_embeddings)) :\n    x = construct_ada_embeddings.iloc[i,:]\n    z = construct_ada_embeddings.apply(lambda row: (cosine(row, x)), axis=1)\n    col_name = str(construct_ada_CSI.iloc[i,0])\n    construct_ada_CSI.loc[:, col_name] = z\nconstruct_ada_CSI.to_csv(\"construct_ada_CSI.csv\") \nprint(\"\\n---- Output: Cosine Similiarity Construct by ada ----\\n\")\n\n\n# cosine similarity between measurement\nmeasurement_ada_CSI = measurement_ada_embeddings[['Measure']]\ndel measurement_ada_embeddings['Measure']\n\nfor i in range(len(measurement_ada_embeddings)) :\n    x = measurement_ada_embeddings.iloc[i,:]\n    z = measurement_ada_embeddings.apply(lambda row: (cosine(row, x)), axis=1)\n    col_name = str(measurement_ada_CSI.iloc[i,0])\n    measurement_ada_CSI.loc[:, col_name] = z\nmeasurement_ada_CSI.to_csv(\"measurement_ada_CSI.csv\") \nprint(\"\\n---- Output: Cosine Similiarity Measurement by ada ----\\n\")\n","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-05-23T08:41:37.022131Z","iopub.execute_input":"2023-05-23T08:41:37.022632Z","iopub.status.idle":"2023-05-23T08:41:38.776943Z","shell.execute_reply.started":"2023-05-23T08:41:37.022588Z","shell.execute_reply":"2023-05-23T08:41:38.775304Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Ranking by Ada for Construct Type, Construct and Measurement","metadata":{}},{"cell_type":"code","source":"test = constructtype_ada_CSI\n\ntest = pd.DataFrame({ 'Constructtype_2': np.tile(test.columns, len(test)), \n                            'Constructtype_1': test['Type of construct'].repeat(test.shape[1]), \n                            'CSI': test.values.ravel()})\ntest = test[test['Constructtype_2'] != 'Type of construct']\n\n# Rearrange column and sort values \ntest = test[[\"Constructtype_1\",\"Constructtype_2\",'CSI']]\ntest = test.sort_values(by = ['CSI'], ascending = False, ignore_index=True)\n\n# Drop row if items are the same \ntest = test[test['Constructtype_1'] != test['Constructtype_2']]\ntest.reset_index(inplace=True, drop=True)\n\n# removing dupclite items pairs e.g. 35-36 & 36-35\n#test = test[[\"Constructtype_1\",\"Constructtype_2\",'CSI']][::2]\n#test.reset_index(inplace=True, drop=True)\n\n#Save data\nranking_constructtype_ada = test.rename(columns={'CSI': 'ada'})\nranking_constructtype_ada.to_csv('ranking_constructtype_ada.csv', index=False)\n\nprint(\"\\n----Output: ranking Construct type by ada in long format with duplicates----\\n\")\n\n\n\n##############################################################################\ntest = construct_ada_CSI\n\ntest = pd.DataFrame({ 'Construct_2': np.tile(test.columns, len(test)), \n                            'Construct_1': test['Construct'].repeat(test.shape[1]), \n                            'CSI': test.values.ravel()})\ntest = test[test['Construct_2'] != 'Construct']\n\n# Rearrange column and sort values \ntest = test[[\"Construct_1\",\"Construct_2\",'CSI']]\ntest = test.sort_values(by = ['CSI'], ascending = False, ignore_index=True)\n\n# Drop row if items are the same \ntest = test[test['Construct_1'] != test['Construct_2']]\ntest.reset_index(inplace=True, drop=True)\n\n# removing dupclite items pairs e.g. 35-36 & 36-35\n#test = test[[\"Construct_1\",\"Construct_2\",'CSI']][::2]\n#test.reset_index(inplace=True, drop=True)\n\n#Save data\nranking_construct_ada = test.rename(columns={'CSI' : 'ada'})\nranking_construct_ada.to_csv('ranking_construct_ada.csv', index=False)\n#ranking_construct_ada.to_excel('ranking_construct_ada.xlsx') \n\nprint(\"\\n----Output: ranking Construct by ada in long format with dupcliates ----\\n\")\n\n\n\n##############################################################################\ntest = measurement_ada_CSI\n\ntest = pd.DataFrame({ 'Measure_2': np.tile(test.columns, len(test)), \n                            'Measure_1': test['Measure'].repeat(test.shape[1]), \n                            'CSI': test.values.ravel()})\ntest = test[test['Measure_2'] != 'Measure']\n\n# Rearrange column and sort values \ntest = test[[\"Measure_1\",\"Measure_2\",'CSI']]\ntest = test.sort_values(by = ['CSI'], ascending = False, ignore_index=True)\n\n# Drop row if items are the same \ntest = test[test['Measure_1'] != test['Measure_2']]\ntest.reset_index(inplace=True, drop=True)\n\n# removing dupclite items pairs e.g. 35-36 & 36-35\n#test = test[[\"Measure_1\",\"Measure_2\",'CSI']][::2]\n#test.reset_index(inplace=True, drop=True)\n\n#Save data\nranking_measurement_ada = test.rename(columns={'CSI' : 'ada'})\nranking_measurement_ada.to_csv('ranking_measurement_ada.csv', index=False)\n#ranking_measurement_ada.to_excel('ranking_construct_ada.xlsx') \n\nprint(\"\\n----Output: ranking Measurement by ada in long format with duplicates----\\n\")\n","metadata":{"execution":{"iopub.status.busy":"2023-05-23T08:41:47.821226Z","iopub.execute_input":"2023-05-23T08:41:47.82179Z","iopub.status.idle":"2023-05-23T08:41:47.933667Z","shell.execute_reply.started":"2023-05-23T08:41:47.821735Z","shell.execute_reply":"2023-05-23T08:41:47.93142Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2. SBert embeddings Google\n\n#### Model setup","metadata":{}},{"cell_type":"code","source":"embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\nembedding_name = \"sBert_embeddings\"","metadata":{"_kg_hide-output":true,"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-07-16T10:57:13.385486Z","iopub.execute_input":"2023-07-16T10:57:13.386853Z","iopub.status.idle":"2023-07-16T10:57:19.418997Z","shell.execute_reply.started":"2023-07-16T10:57:13.3868Z","shell.execute_reply":"2023-07-16T10:57:19.417593Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)e9125/.gitattributes:   0%|          | 0.00/1.18k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"88c87ec36ded4b10a9500990cb66ee7c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1711ce023a0f461480b4eb4474da48eb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)7e55de9125/README.md:   0%|          | 0.00/10.6k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8701fe602438412e8f9966a41d6bfbee"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)55de9125/config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3d82212eddbe4b07bfd86edf89358571"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)ce_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5fba3ba6d2014e1084a868049963bb30"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)125/data_config.json:   0%|          | 0.00/39.3k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"88de8d5fd1df4a6a980cac8e276d7c67"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading pytorch_model.bin:   0%|          | 0.00/90.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"43a00465a46d4ed798a6f7e17a9fe346"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)nce_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"28f65681b75a42a1a199252ef37a480d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)cial_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eeec3bf58f29402daf92ddec47f3a8c6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)e9125/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"295109a85b2842a5bc4ef43f188ab96a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)okenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8c4c4fa3ed5b4f498413e45cce7f22d3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)9125/train_script.py:   0%|          | 0.00/13.2k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"95d9de26599442f38044f54cd8fe9182"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)7e55de9125/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eba5136184cf432e9a6cf6ccbd4343e7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)5de9125/modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2d3714fa9f5d44d1b14b666e056ab121"}},"metadata":{}}]},{"cell_type":"markdown","source":"#### Embeddings","metadata":{}},{"cell_type":"code","source":"df[embedding_name] = df[\"Item_English\"].apply(lambda x: embedding_model.encode(x))\n\n# Save output data\ncolumn_list=[\"Type of construct\", \"Construct\", \"Measure\", \"Item_English\", \"sBert_embeddings\"]\ndf.to_csv(embedding_name + '.csv', columns = column_list, index=False)\n#df.to_excel(embedding_name + '.xlsx', columns = column_list, index=False)  ","metadata":{"_kg_hide-output":true,"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-05-23T08:43:05.379678Z","iopub.execute_input":"2023-05-23T08:43:05.380176Z","iopub.status.idle":"2023-05-23T08:43:22.881616Z","shell.execute_reply.started":"2023-05-23T08:43:05.38013Z","shell.execute_reply":"2023-05-23T08:43:22.87984Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Cosine Similarity Matrix","metadata":{}},{"cell_type":"code","source":"minrange = -1\nmaxrange = 1\n\n#setting up df for cosine based on sBert\nCSI_sBert = df[['Item_English', 'sBert_embeddings']]\n\nfor i in range(len(CSI_sBert)) :\n    x = CSI_sBert.iloc[i,1]\n    z = CSI_sBert.apply(lambda row: (cosine(row['sBert_embeddings'], x)), axis=1)\n    y = (z - minrange)/(maxrange-minrange) #Force the CSI to be within 0:1 range\n    col_name = str(i) + '. ' + str(CSI_sBert.iloc[i,0])\n    CSI_sBert.loc[:, col_name] = y\n\nCSI_sBert.to_csv(\"CSI_sBert.csv\")    \n#CSI_sBert.to_excel('CSI_sBert.xlsx')  \n\nprint(\"\\n----Output: Cosine Similariy by sBert ----\\n\")","metadata":{"_kg_hide-output":true,"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-05-23T08:48:32.080176Z","iopub.execute_input":"2023-05-23T08:48:32.081677Z","iopub.status.idle":"2023-05-23T08:48:40.349494Z","shell.execute_reply.started":"2023-05-23T08:48:32.081613Z","shell.execute_reply":"2023-05-23T08:48:40.347857Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Cosine Similarity Ranking ","metadata":{}},{"cell_type":"code","source":"ranking_sBert = CSI_sBert\n\n# Drop embedding column\nranking_sBert = ranking_sBert.drop(['sBert_embeddings'], axis=1)\n\n# Create Long format\nranking_sBert = pd.DataFrame({ 'Item_2': np.tile(ranking_sBert.columns, len(ranking_sBert)), 'Item_1': ranking_sBert.Item_English.repeat(ranking_sBert.shape[1]), 'CSI': ranking_sBert.values.ravel()})\nranking_sBert = ranking_sBert[ranking_sBert['Item_2'] != 'Item_English']\n\n#Adding index columns\nranking_sBert['Index_1'] = ranking_sBert.index\nranking_sBert['Index_2'], ranking_sBert['Item_2'] = ranking_sBert['Item_2'].str.split('.', 1).str\nranking_sBert['Index_2'] = ranking_sBert['Index_2'].astype(int)\n\n# Rearrange column and sort values \nranking_sBert = ranking_sBert[[\"Index_1\",\"Item_1\",\"Index_2\",'Item_2', 'CSI']]\nranking_sBert = ranking_sBert.sort_values(by = ['CSI'], ascending = False, ignore_index=True)\n\n# Drop row if items are the same \nranking_sBert = ranking_sBert[ranking_sBert['Index_1'] != ranking_sBert['Index_2']]\nranking_sBert.reset_index(inplace=True, drop=True)\n\n#Save data without removing duplicates\nranking_sBert.to_csv('ranking_sBert_duplipcates.csv', index=False)\nranking_sBert.to_excel('ranking_sBert_duplicates.xlsx') \nprint(\"\\n----Output: Ranking by sBert with duplicates in Long Format----\\n\")\n\n\n# removing dupclite items pairs e.g. 35-36 & 36-35\nranking_sBert = ranking_sBert[['Index_1', 'Item_1', 'Index_2', 'Item_2', 'CSI']][::2]\nranking_sBert.reset_index(inplace=True, drop=True)\n\n#Save data\nranking_sBert.to_csv('ranking_sBert.csv', index=False)\n#ranking_sBert.to_excel('ranking_sBert.xlsx') \n\nprint(\"\\n----Output: Ranking by sBert in Long Format ----\\n\")\n","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-05-23T08:48:47.709178Z","iopub.execute_input":"2023-05-23T08:48:47.709635Z","iopub.status.idle":"2023-05-23T08:49:23.278445Z","shell.execute_reply.started":"2023-05-23T08:48:47.709596Z","shell.execute_reply":"2023-05-23T08:49:23.276833Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Average embeddings per Construct type Construct and Measurement","metadata":{}},{"cell_type":"code","source":"test = df.loc[:,('Type of construct', 'Construct', 'Measure', 'Item_English', 'sBert_embeddings')]\n\n#split embedding over multiple columns and concatenate them with original columns\ntest = pd.concat([test, test[\"sBert_embeddings\"].apply(pd.Series)], axis = 1)\n\n#average embedding vector per ...\nconstructtype_sbert_embeddings = test.groupby(\"Type of construct\").mean()\nconstructtype_sbert_embeddings.reset_index(inplace=True)\nconstructtype_sbert_embeddings.to_csv(\"constructtype_sbert_embeddings.csv\") \nprint(\"\\n----Output: Average Embeddings for Construct type by sBert ----\\n\")\n\nconstruct_sbert_embeddings = test.groupby(\"Construct\").mean()\nconstruct_sbert_embeddings.reset_index(inplace=True)\nconstruct_sbert_embeddings.to_csv(\"construct_sbert_embeddings.csv\") \nprint(\"\\n----Output: Average Embeddings for Construct by sBert ----\\n\")\n\nmeasurement_sbert_embeddings = test.groupby(\"Measure\").mean()\nmeasurement_sbert_embeddings.reset_index(inplace=True)\nmeasurement_sbert_embeddings.to_csv(\"measurement_sbert_embeddings.csv\") \nprint(\"\\n----Output: Average Embeddings for Measurementby sBert ----\\n\")\n\n\n# cosine similarity between Type of construct\nconstructtype_sbert_CSI = constructtype_sbert_embeddings[['Type of construct']]\ndel constructtype_sbert_embeddings['Type of construct']\n\nfor i in range(len(constructtype_sbert_embeddings)) :\n    x = constructtype_sbert_embeddings.iloc[i,:]\n    z = constructtype_sbert_embeddings.apply(lambda row: (cosine(row, x)), axis=1)\n    y = (z - minrange)/(maxrange-minrange)\n    col_name = str(constructtype_sbert_CSI.iloc[i,0])\n    constructtype_sbert_CSI.loc[:, col_name] = y\nconstructtype_sbert_CSI.to_csv(\"constructtype_sbert_CSI.csv\")    \nprint(\"\\n----Output: CSI between Construct type by sBert ----\\n\")\n\n\n# cosine similarity between construct\nconstruct_sbert_CSI = construct_sbert_embeddings[['Construct']]\ndel construct_sbert_embeddings['Construct']\n\nfor i in range(len(construct_sbert_embeddings)) :\n    x = construct_sbert_embeddings.iloc[i,:]\n    z = construct_sbert_embeddings.apply(lambda row: (cosine(row, x)), axis=1)\n    y = (z - minrange)/(maxrange-minrange)\n    col_name = str(construct_sbert_CSI.iloc[i,0])\n    construct_sbert_CSI.loc[:, col_name] = y\nconstruct_sbert_CSI.to_csv(\"construct_sbert_CSI.csv\") \nprint(\"\\n----Output: CSI between Construct  by sBert ----\\n\")\n\n# cosine similarity between measurement\nmeasurement_sbert_CSI = measurement_sbert_embeddings[['Measure']]\ndel measurement_sbert_embeddings['Measure']\n\nfor i in range(len(measurement_sbert_embeddings)) :\n    x = measurement_sbert_embeddings.iloc[i,:]\n    z = measurement_sbert_embeddings.apply(lambda row: (cosine(row, x)), axis=1)\n    y = (z - minrange)/(maxrange-minrange)\n    col_name = str(measurement_sbert_CSI.iloc[i,0])\n    measurement_sbert_CSI.loc[:, col_name] = y\nmeasurement_sbert_CSI.to_csv(\"measurement_sbert_CSI.csv\") \nprint(\"\\n----Output: CSI between Measurement by sBert ----\\n\")\n\n","metadata":{"execution":{"iopub.status.busy":"2023-05-23T08:50:21.815856Z","iopub.execute_input":"2023-05-23T08:50:21.817699Z","iopub.status.idle":"2023-05-23T08:50:23.06203Z","shell.execute_reply.started":"2023-05-23T08:50:21.817632Z","shell.execute_reply":"2023-05-23T08:50:23.060397Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Cosine Similarity Between Construct type, Construct and Measurement","metadata":{}},{"cell_type":"code","source":"test = constructtype_sbert_CSI\n\ntest = pd.DataFrame({ 'Constructtype_2': np.tile(test.columns, len(test)), \n                            'Constructtype_1': test['Type of construct'].repeat(test.shape[1]), \n                            'CSI': test.values.ravel()})\ntest = test[test['Constructtype_2'] != 'Type of construct']\n\n# Rearrange column and sort values \ntest = test[[\"Constructtype_1\",\"Constructtype_2\",'CSI']]\ntest = test.sort_values(by = ['CSI'], ascending = False, ignore_index=True)\n\n# Drop row if items are the same \ntest = test[test['Constructtype_1'] != test['Constructtype_2']]\ntest.reset_index(inplace=True, drop=True)\n\n# removing dupclite items pairs e.g. 35-36 & 36-35\n#test = test[[\"Constructtype_1\",\"Constructtype_2\",'CSI']][::2]\n#test.reset_index(inplace=True, drop=True)\n\n#Save data\nranking_constructtype_sbert = test.rename(columns={'CSI': 'sbert'})\nranking_constructtype_sbert.to_csv('ranking_constructtype_sbert.csv', index=False)\n#ranking_constructtype_sbert.to_excel('ranking_constructtype_sbert.xlsx') \n\nprint(\"\\n----Output: ranking Construct type by sbert in long format with duplicates----\\n\")\n\n##############################################################################\n\ntest = construct_sbert_CSI\n\ntest = pd.DataFrame({ 'Construct_2': np.tile(test.columns, len(test)), \n                            'Construct_1': test['Construct'].repeat(test.shape[1]), \n                            'CSI': test.values.ravel()})\ntest = test[test['Construct_2'] != 'Construct']\n\n# Rearrange column and sort values \ntest = test[[\"Construct_1\",\"Construct_2\",'CSI']]\ntest = test.sort_values(by = ['CSI'], ascending = False, ignore_index=True)\n\n# Drop row if items are the same \ntest = test[test['Construct_1'] != test['Construct_2']]\ntest.reset_index(inplace=True, drop=True)\n\n# removing dupclite items pairs e.g. 35-36 & 36-35\n#test = test[[\"Construct_1\",\"Construct_2\",'CSI']][::2]\n#test.reset_index(inplace=True, drop=True)\n\n#Save data\nranking_construct_sbert = test.rename(columns={'CSI' : 'sbert'})\nranking_construct_sbert.to_csv('ranking_construct_sbert.csv', index=False)\n#ranking_construct_sbert.to_excel('ranking_construct_sbert.xlsx') \n\nprint(\"\\n----Output: ranking Construct by sbert in long format with dupcliates----\\n\")\n\n##############################################################################\n\ntest = measurement_sbert_CSI\n\ntest = pd.DataFrame({ 'Measure_2': np.tile(test.columns, len(test)), \n                            'Measure_1': test['Measure'].repeat(test.shape[1]), \n                            'CSI': test.values.ravel()})\ntest = test[test['Measure_2'] != 'Measure']\n\n# Rearrange column and sort values \ntest = test[[\"Measure_1\",\"Measure_2\",'CSI']]\ntest = test.sort_values(by = ['CSI'], ascending = False, ignore_index=True)\n\n# Drop row if items are the same \ntest = test[test['Measure_1'] != test['Measure_2']]\ntest.reset_index(inplace=True, drop=True)\n\n# removing dupclite items pairs e.g. 35-36 & 36-35\n#test = test[[\"Measure_1\",\"Measure_2\",'CSI']][::2]\n#test.reset_index(inplace=True, drop=True)\n\n#Save data\nranking_measurement_sbert = test.rename(columns={'CSI' : 'sbert'})\nranking_measurement_sbert.to_csv('ranking_measurement_sbert.csv', index=False)\n#ranking_measurement_sbert.to_excel('ranking_measurement_sbert.xlsx') \n\nprint(\"\\n----Output: ranking Measurement by sbert in long format with duplicates----\\n\")\n","metadata":{"execution":{"iopub.status.busy":"2023-05-23T08:50:47.56834Z","iopub.execute_input":"2023-05-23T08:50:47.568872Z","iopub.status.idle":"2023-05-23T08:50:47.67501Z","shell.execute_reply.started":"2023-05-23T08:50:47.568829Z","shell.execute_reply":"2023-05-23T08:50:47.673556Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 3. Universal Sentence Encoder Google","metadata":{}},{"cell_type":"markdown","source":"#### Model setup","metadata":{}},{"cell_type":"code","source":"# Load pre-trained universal sentence encoder model\nembedding_model = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\nembedding_name = \"USE_embeddings\"\n","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-05-23T08:50:57.897049Z","iopub.execute_input":"2023-05-23T08:50:57.897974Z","iopub.status.idle":"2023-05-23T08:51:37.297736Z","shell.execute_reply.started":"2023-05-23T08:50:57.897924Z","shell.execute_reply":"2023-05-23T08:51:37.296161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Embeddings","metadata":{}},{"cell_type":"code","source":"x = embedding_model(df[\"Item_English\"])\n#print(len(df[\"Item_English\"]))\n#print(len(x))\n#print(df[\"Item_English\"].shape)\n#print(x.shape)\n\n# Tenserflow to panda dataframe \ny = x.numpy()\nh = pd.DataFrame(y)\nh.shape\n\n\n#cosine(h.loc[269,0:511], h.loc[269, 0:511])\n#Combine 512 dimensions into one column\ndf[embedding_name] = h.astype(str).agg(', '.join, axis=1)\ndf[embedding_name] = h.astype(str).agg(', '.join, axis=1)\n\n# Save output data\ncolumn_list=[\"Type of construct\", \"Construct\", \"Measure\", \"Item_English\", \"USE_embeddings\"]\ndf.to_csv(embedding_name + '.csv', columns = column_list, index=False)\n#df.to_excel(embedding_name + '.xlsx', columns = column_list, index=False)  ","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-05-23T08:51:45.086399Z","iopub.execute_input":"2023-05-23T08:51:45.087364Z","iopub.status.idle":"2023-05-23T08:51:46.599075Z","shell.execute_reply.started":"2023-05-23T08:51:45.087309Z","shell.execute_reply":"2023-05-23T08:51:46.597367Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Cosine Similarity Matrix","metadata":{}},{"cell_type":"code","source":"#setting up df for cosine based on OpenAi\nCSI_USE_copy = pd.concat([df['Item_English'], h], axis=1)\nCSI_USE = pd.DataFrame(df['Item_English'])\n\n#calculate cosine and setting up df\nfor i in range(len(CSI_USE)) :\n    x = CSI_USE_copy.iloc[i,1:512]\n    z = CSI_USE_copy.apply(lambda row: (cosine(row[1:512], x)), axis=1)\n    y = (z - minrange)/(maxrange-minrange)\n    col_name = str(i) + '. ' + str(CSI_USE.iloc[i,0])\n    CSI_USE.loc[:, col_name] = y\n    \nCSI_USE.to_csv(\"CSI_USE.csv\")  \n#CSI_USE.to_excel('CSI_USE.xlsx')  \n\nprint(\"\\n----Output: Cosine Similarity by USE ----\\n\")\n","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-05-23T08:53:20.284096Z","iopub.execute_input":"2023-05-23T08:53:20.285419Z","iopub.status.idle":"2023-05-23T08:56:58.132565Z","shell.execute_reply.started":"2023-05-23T08:53:20.285338Z","shell.execute_reply":"2023-05-23T08:56:58.131013Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Cosine Similarity Ranking ","metadata":{}},{"cell_type":"code","source":"ranking_USE = CSI_USE\n\n# Drop embedding column\n#ranking_USE = ranking_USE.drop(['sBert_embeddings'], axis=1)\n\n# Create Long format\nranking_USE = pd.DataFrame({ 'Item_2': np.tile(ranking_USE.columns, len(ranking_USE)), 'Item_1': ranking_USE.Item_English.repeat(ranking_USE.shape[1]), 'CSI': ranking_USE.values.ravel()})\nranking_USE = ranking_USE[ranking_USE['Item_2'] != 'Item_English']\n\n#Adding index columns\nranking_USE['Index_1'] = ranking_USE.index\nranking_USE['Index_2'], ranking_USE['Item_2'] = ranking_USE['Item_2'].str.split('.', 1).str\nranking_USE['Index_2'] = ranking_USE['Index_2'].astype(int)\n\n# Rearrange column and sort values \nranking_USE = ranking_USE[[\"Index_1\",\"Item_1\",\"Index_2\",'Item_2', 'CSI']]\nranking_USE = ranking_USE.sort_values(by = ['CSI'], ascending = False, ignore_index=True)\n\n# Drop row if items are the same \nranking_USE = ranking_USE[ranking_USE['Index_1'] != ranking_USE['Index_2']]\nranking_USE.reset_index(inplace=True, drop=True)\n\n#Save data\nranking_USE.to_csv('ranking_USE_duplicates.csv', index=False)\n#ranking_USE.to_excel('ranking_USE_duplicates.xlsx') \nprint(\"\\n----Output: ranking by USE with duplicates in Long Format----\\n\")\n\n\n# removing dupclite items pairs e.g. 35-36 & 36-35\nranking_USE = ranking_USE[['Index_1', 'Item_1', 'Index_2', 'Item_2', 'CSI']][::2]\nranking_USE.reset_index(inplace=True, drop=True)\n\n#Save data\nranking_USE.to_csv('ranking_USE.csv', index=False)\n#ranking_USE.to_excel('ranking_USE.xlsx') \n\nprint(\"\\n----Output: ranking by USE in Long Format----\\n\")\n","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-05-23T08:57:24.419454Z","iopub.execute_input":"2023-05-23T08:57:24.420024Z","iopub.status.idle":"2023-05-23T08:57:27.16611Z","shell.execute_reply.started":"2023-05-23T08:57:24.41998Z","shell.execute_reply":"2023-05-23T08:57:27.16458Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Averages Embedding per construct type construct and measurment","metadata":{}},{"cell_type":"code","source":"test = df.loc[:,('Type of construct', 'Construct', 'Measure', 'Item_English')]\n#split embedding over multiple columns and concatenate them with original columns\ntest = pd.concat([test, h], axis = 1)\n\n#average embedding vector per ...\nconstructtype_USE_embeddings = test.groupby(\"Type of construct\").mean()\nconstructtype_USE_embeddings.reset_index(inplace=True)\nconstructtype_USE_embeddings.to_csv(\"constructtype_USE_embeddings.csv\") \nprint(\"\\n----Output: Average embeddings per COnstruct type by USE----\\n\")\n\nconstruct_USE_embeddings = test.groupby(\"Construct\").mean()\nconstruct_USE_embeddings.reset_index(inplace=True)\nconstruct_USE_embeddings.to_csv(\"construct_USE_embeddings.csv\") \nprint(\"\\n----Output: Average embeddings per COnstruct by USE----\\n\")\n\n\nmeasurement_USE_embeddings = test.groupby(\"Measure\").mean()\nmeasurement_USE_embeddings.reset_index(inplace=True)\nmeasurement_USE_embeddings.to_csv(\"measurement_USE_embeddings.csv\") \nprint(\"\\n----Output: Average embeddings per Measurement by USE----\\n\")\n\n\n# cosine similarity between Type of construct\nconstructtype_USE_CSI = constructtype_USE_embeddings[['Type of construct']]\ndel constructtype_USE_embeddings['Type of construct']\n\nfor i in range(len(constructtype_USE_embeddings)) :\n    x = constructtype_USE_embeddings.iloc[i,:]\n    z = constructtype_USE_embeddings.apply(lambda row: (cosine(row, x)), axis=1)\n    y = (z - minrange)/(maxrange-minrange)\n    col_name = str(constructtype_USE_CSI.iloc[i,0])\n    constructtype_USE_CSI.loc[:, col_name] = y\nconstructtype_USE_CSI.to_csv(\"constructtype_USE_CSI.csv\")    \nprint(\"\\n----Output: Cosine Similarity per Construct type by USE----\\n\")\n\n# cosine similarity between construct\nconstruct_USE_CSI = construct_USE_embeddings[['Construct']]\ndel construct_USE_embeddings['Construct']\n\nfor i in range(len(construct_USE_embeddings)) :\n    x = construct_USE_embeddings.iloc[i,:]\n    z = construct_USE_embeddings.apply(lambda row: (cosine(row, x)), axis=1)\n    y = (z - minrange)/(maxrange-minrange)\n    col_name = str(construct_USE_CSI.iloc[i,0])\n    construct_USE_CSI.loc[:, col_name] = y\nconstruct_USE_CSI.to_csv(\"construct_USE_CSI.csv\") \nprint(\"\\n----Output: Cosine Similarity per Construct by USE----\\n\")\n\n\n# cosine similarity between measurement\nmeasurement_USE_CSI = measurement_USE_embeddings[['Measure']]\ndel measurement_USE_embeddings['Measure']\n\nfor i in range(len(measurement_USE_embeddings)) :\n    x = measurement_USE_embeddings.iloc[i,:]\n    z = measurement_USE_embeddings.apply(lambda row: (cosine(row, x)), axis=1)\n    y = (z - minrange)/(maxrange-minrange)\n    col_name = str(measurement_USE_CSI.iloc[i,0])\n    measurement_USE_CSI.loc[:, col_name] = y\nmeasurement_USE_CSI.to_csv(\"measurement_USE_CSI.csv\") \nprint(\"\\n----Output: Cosine Similarity per Measurement by USE----\\n\")\n\n","metadata":{"execution":{"iopub.status.busy":"2023-05-23T08:57:51.300846Z","iopub.execute_input":"2023-05-23T08:57:51.301347Z","iopub.status.idle":"2023-05-23T08:57:52.481376Z","shell.execute_reply.started":"2023-05-23T08:57:51.301304Z","shell.execute_reply":"2023-05-23T08:57:52.479881Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = constructtype_USE_CSI\n\ntest = pd.DataFrame({ 'Constructtype_2': np.tile(test.columns, len(test)), \n                            'Constructtype_1': test['Type of construct'].repeat(test.shape[1]), \n                            'CSI': test.values.ravel()})\ntest = test[test['Constructtype_2'] != 'Type of construct']\n\n# Rearrange column and sort values \ntest = test[[\"Constructtype_1\",\"Constructtype_2\",'CSI']]\ntest = test.sort_values(by = ['CSI'], ascending = False, ignore_index=True)\n\n# Drop row if items are the same \ntest = test[test['Constructtype_1'] != test['Constructtype_2']]\ntest.reset_index(inplace=True, drop=True)\n\n# removing dupclite items pairs e.g. 35-36 & 36-35\n#test = test[[\"Constructtype_1\",\"Constructtype_2\",'CSI']][::2]\n#test.reset_index(inplace=True, drop=True)\n\n#Save data\nranking_constructtype_USE = test.rename(columns={'CSI': 'USE'})\nranking_constructtype_USE.to_csv('ranking_constructtype_USE.csv', index=False)\n#ranking_constructtype_USE.to_excel('ranking_constructtype_USE.xlsx') \n\nprint(\"\\n----Output: ranking Construct type by USE in long format with duplicates----\\n\")\n\n##############################################################################\n\ntest = construct_USE_CSI\n\ntest = pd.DataFrame({ 'Construct_2': np.tile(test.columns, len(test)), \n                            'Construct_1': test['Construct'].repeat(test.shape[1]), \n                            'CSI': test.values.ravel()})\ntest = test[test['Construct_2'] != 'Construct']\n\n# Rearrange column and sort values \ntest = test[[\"Construct_1\",\"Construct_2\",'CSI']]\ntest = test.sort_values(by = ['CSI'], ascending = False, ignore_index=True)\n\n# Drop row if items are the same \ntest = test[test['Construct_1'] != test['Construct_2']]\ntest.reset_index(inplace=True, drop=True)\n\n# removing dupclite items pairs e.g. 35-36 & 36-35\n#test = test[[\"Construct_1\",\"Construct_2\",'CSI']][::2]\n#test.reset_index(inplace=True, drop=True)\n\n#Save data\nranking_construct_USE = test.rename(columns={'CSI' : 'USE'})\nranking_construct_USE.to_csv('ranking_construct_USE.csv', index=False)\n#ranking_construct_USE.to_excel('ranking_construct_USE.xlsx') \n\n##############################################################################\n\nprint(\"\\n----Output: ranking Construct by USE in long format with dupcliates----\\n\")\n\ntest = measurement_USE_CSI\n\ntest = pd.DataFrame({ 'Measure_2': np.tile(test.columns, len(test)), \n                            'Measure_1': test['Measure'].repeat(test.shape[1]), \n                            'CSI': test.values.ravel()})\ntest = test[test['Measure_2'] != 'Measure']\n\n# Rearrange column and sort values \ntest = test[[\"Measure_1\",\"Measure_2\",'CSI']]\ntest = test.sort_values(by = ['CSI'], ascending = False, ignore_index=True)\n\n# Drop row if items are the same \ntest = test[test['Measure_1'] != test['Measure_2']]\ntest.reset_index(inplace=True, drop=True)\n\n# removing dupclite items pairs e.g. 35-36 & 36-35\n#test = test[[\"Measure_1\",\"Measure_2\",'CSI']][::2]\n#test.reset_index(inplace=True, drop=True)\n\n#Save data\nranking_measurement_USE = test.rename(columns={'CSI' : 'USE'})\nranking_measurement_USE.to_csv('ranking_measurement_USE.csv', index=False)\n#ranking_measurement_USE.to_excel('ranking_measurement_USE.xlsx') \n\nprint(\"\\n----Output: ranking Measurement by USE in long format with dupcliates----\\n\")\n","metadata":{"execution":{"iopub.status.busy":"2023-05-23T08:58:05.978497Z","iopub.execute_input":"2023-05-23T08:58:05.979026Z","iopub.status.idle":"2023-05-23T08:58:06.082987Z","shell.execute_reply.started":"2023-05-23T08:58:05.978979Z","shell.execute_reply":"2023-05-23T08:58:06.081095Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]}]}